{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e42716c5-d52d-416f-ac45-f04499563342",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding:utf-8 -*-\n",
    "__author__ = 'Author'\n",
    "__email__ = 'Email'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c113d57f-5c19-4fc0-9b9d-713706ae1c40",
   "metadata": {},
   "source": [
    "# SemEval 2024 Task 1: Semantic Textual Relatedness (STR)\n",
    "(These instructions are adapted from the [official ones](https://github.com/semantic-textual-relatedness/Semantic_Relatedness_SemEval2024/blob/main/STR_Baseline.ipynb).) \\\n",
    "[Dataset](https://github.com/semantic-textual-relatedness/Semantic_Relatedness_SemEval2024#dataset) | \n",
    "[Languages](https://github.com/semantic-textual-relatedness/Semantic_Relatedness_SemEval2024#languages) | \n",
    "[Shared Task Starter Kit](https://github.com/semantic-textual-relatedness/Semantic_Relatedness_SemEval2024#shared-task-starter-kit) | \n",
    "[Citing This Work](https://github.com/semantic-textual-relatedness/Semantic_Relatedness_SemEval2024#citing-this-work)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3624b7-eb29-4288-959a-747a306a63c2",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Welcome to the SemEval 2024 Task 1: Semantic Textual Relatedness (STR) instructional Jupyter Notebook. \\\n",
    "This guide is crafted to provide you with a comprehensive roadmap and essential resources to excel in this exciting challenge.\n",
    "\n",
    "### Tracks\n",
    "SemEval 2024 Task 1 offers three distinct tracks, each focusing on a unique aspect of Semantic Textual Relatedness. \\\n",
    "Understanding these tracks will help you decide where your submission fits best:\n",
    "+ **Track A: Supervised** \\\n",
    "  This track is for submissions that utilize labeled data in the target language. \\\n",
    "  It's ideal if you're leveraging datasets with predefined semantic relationships for model training.\n",
    "+ **Track B: Unsupervised** \\\n",
    "  Choose this track if your submission does not use labeled data in any language. \\\n",
    "  This track is suitable for approaches that rely on unsupervised learning techniques or intrinsic textual features.\n",
    "+ **Track C: Cross-lingual** \\\n",
    "  If your submission involves using labeled data from a language other than the target language, this is the track for you.\n",
    "  Itâ€™s designed for exploring semantic relationships across different languages.\n",
    "\n",
    "### Choosing Your Track\n",
    "When deciding which track to submit to, consider the type of data and methods you are using:\n",
    "+ Opt for Track A if your approach is built on labeled data specifically in the target language.\n",
    "+ Choose Track B if your method operates without any labeled data, regardless of the language.\n",
    "+ Select Track C if you are employing labeled data from a language different from the target language, focusing on cross-lingual semantic understanding.\n",
    "\n",
    "### Languages\n",
    "\n",
    "The STR task focuses on the following 14 languages:\n",
    "\n",
    "\n",
    "1. Afrikaans (_afr_ released)\n",
    "2. Algerian Arabic (_arq_ released)\n",
    "4. Amharic (_amh_ released)\n",
    "5. English (_eng_ released)\n",
    "6. Hausa (_hau_ released)\n",
    "7. Indonesian\n",
    "8. Hindi\n",
    "9. Kinyarwanda\n",
    "10. Marathi (_mar_ released)\n",
    "11. Modern Standard Arabic (_arb_ released)\n",
    "12. Moroccan Arabic (_ary_ released)\n",
    "13. Punjabi\n",
    "14. Spanish (_esp_ released)\n",
    "15. Telugu (_tel_ released)\n",
    "\n",
    "### Datasets\n",
    "The STR dataset is available in the data folder or can be downloaded from Hugging Face (coming soon).\n",
    "+ [TrackA Folder](https://github.com/semantic-textual-relatedness/Semantic_Relatedness_SemEval2024/tree/main/Track%20A)\n",
    "+ [TrackB Folder](https://github.com/semantic-textual-relatedness/Semantic_Relatedness_SemEval2024/tree/main/Track%20B)\n",
    "+ [TrackC Folder](https://github.com/semantic-textual-relatedness/Semantic_Relatedness_SemEval2024/tree/main/Track%20C)\n",
    "\n",
    "### Please Join\n",
    "+ [Join Google Group](https://groups.google.com/forum/#!forum/semrel-semeval-participants/join)\n",
    "+ [Follow us on Twitter](https://twitter.com/SemRel2024)\n",
    "+ [Join Task Slack Channel](https://join.slack.com/t/semrelsemeval2024/shared_invite/zt-2446ppar5-62koodIDFC9bCRMlR0ATkA)\n",
    "\n",
    "### Reference\n",
    "+ https://semeval.github.io/SemEval2024/tasks\n",
    "+ https://semantic-textual-relatedness.github.io/\n",
    "+ https://codalab.lisn.upsaclay.fr/competitions/15715\n",
    "+ https://github.com/semantic-textual-relatedness/Semantic_Relatedness_SemEval2024\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ddb928-dbae-4be4-a0d9-1b76cc3dc24d",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961bbe42-b83a-45e1-852d-ecf90041170f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "---\n",
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0599342-1390-4b25-b3f7-fc111d89dc34",
   "metadata": {},
   "source": [
    "### Virtual Environment\n",
    "A virtual environment allows you to manage dependencies and isolate your project to prevent any conflicts with other work you may be doing. \\\n",
    "For this project, we highly recommend using a virtual environment to ensure a smooth and consistent development experience. \\\n",
    "There are several tools available for creating virtual environments. \\\n",
    "Two popular options are: [pyenv](https://github.com/pyenv/pyenv) and [conda](https://medium.com/@mrshininnnnn/virtual-environments-for-python-6ab3802fe87e).\n",
    "\n",
    "### Required Libraries\n",
    "+ numpy >= 1.26.2\n",
    "+ pandas >= 2.1.4\n",
    "\n",
    "Simply run:\n",
    "```\n",
    "pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33b0b71-eedd-4a44-90f4-d58384750f6a",
   "metadata": {},
   "source": [
    "---\n",
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f00aecca-6524-4d26-a48e-cffde145de5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# dependency\n",
    "# built-in\n",
    "import os, random\n",
    "# public\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# private\n",
    "from config import Config\n",
    "from src.utils import helper\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d5c026-3025-4d05-9043-6493abe5575e",
   "metadata": {},
   "source": [
    "---\n",
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4565e4ca-d0ff-4980-8384-a313489639f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 0\n",
      "track: a\n",
      "tgt_lan: eng\n",
      "method: base\n",
      "CURR_PATH: ./\n",
      "RESOURCE_PATH: ./res\n",
      "DATA_PATH: ./res/data\n",
      "TRACK_PATH: ./res/data/a\n",
      "LAN_PATH: ./res/data/a/eng\n",
      "TRAIN_CSV: ./res/data/a/eng/eng_train.csv\n",
      "DEV_CSV: ./res/data/a/eng/eng_dev.csv\n",
      "LOG_PATH: ./res/log/a/eng/base/0\n",
      "LOG_TXT: ./res/log/a/eng/base/0/console_log.txt\n",
      "RESULTS_PATH: ./res/results/a/eng/base\n",
      "RESULTS_CSV: ./res/results/a/eng/base/0.csv\n"
     ]
    }
   ],
   "source": [
    "# initialize the config class\n",
    "config = Config()\n",
    "random.seed(config.seed)\n",
    "np.random.seed(config.seed)\n",
    "for k, v in config.__dict__.items():\n",
    "    print(f'{k}: {v}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29f14e8-5830-4e31-bdb7-bd34bfba99a3",
   "metadata": {},
   "source": [
    "---\n",
    "## Datasets\n",
    "\n",
    "The training data will have a real-values semantic textual relatedness score (between 0 and 1) for a pair of English-language sentences.\n",
    "\n",
    "The data is structured as a CSV file with the following fields:\n",
    "- PairID: a unique identifier for the sentence pair\n",
    "- Text: two sentences separated by a newline ('\\n') character\n",
    "- Score: the semantic textual relatedness score for the two sentences\n",
    "\n",
    "Below we will show you how to load and re-format the provided data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "79fca658-e75e-4a0a-bc2f-546d28422fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./res/data/a/eng/eng_train.csv', './res/data/a/eng/eng_dev.csv')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# path from config\n",
    "config.TRAIN_CSV, config.DEV_CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c356948a-b347-4c3e-84b4-eec4d25a4ee6",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ade5c1f6-1895-4ec2-94a3-ce5ae75b97f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read train csv\n",
    "raw_train_df = pd.read_csv(config.TRAIN_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a7887cc-5771-4781-b125-d15c83ec6d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5500 entries, 0 to 5499\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   PairID  5500 non-null   object \n",
      " 1   Text    5500 non-null   object \n",
      " 2   Score   5500 non-null   float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 129.0+ KB\n"
     ]
    }
   ],
   "source": [
    "raw_train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50db4853-2b56-4e86-a8e3-fb960970a824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PairID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENG-train-0000</td>\n",
       "      <td>It that happens, just pull the plug.\\nif that ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENG-train-0001</td>\n",
       "      <td>A black dog running through water.\\nA black do...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENG-train-0002</td>\n",
       "      <td>I've been searchingthe entire abbey for you.\\n...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENG-train-0003</td>\n",
       "      <td>If he is good looking and has a good personali...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENG-train-0004</td>\n",
       "      <td>She does not hate you, she is just annoyed wit...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           PairID                                               Text  Score\n",
       "0  ENG-train-0000  It that happens, just pull the plug.\\nif that ...    1.0\n",
       "1  ENG-train-0001  A black dog running through water.\\nA black do...    1.0\n",
       "2  ENG-train-0002  I've been searchingthe entire abbey for you.\\n...    1.0\n",
       "3  ENG-train-0003  If he is good looking and has a good personali...    1.0\n",
       "4  ENG-train-0004  She does not hate you, she is just annoyed wit...    1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "569b15de-e092-493e-b29e-af2b6152d01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_xs1, train_xs2 = map(list, zip(*[tuple(row['Text'].split('\\n')) for idx, row in raw_train_df.iterrows()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75930b84-fe3c-4205-b757-cb291db3be7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ys = raw_train_df.Score.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d21e0b-1473-4689-94ee-70ea00ccd4ce",
   "metadata": {},
   "source": [
    "#### Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8bb499e-702b-40ff-a47a-efb748b6d825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dev csv\n",
    "raw_dev_df = pd.read_csv(config.DEV_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef9ac675-4b8b-470f-964b-f1f65e292188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 250 entries, 0 to 249\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   PairID  250 non-null    object\n",
      " 1   Text    250 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 4.0+ KB\n"
     ]
    }
   ],
   "source": [
    "raw_dev_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37e1a3f8-6a8f-4497-b74b-26c5f0f644e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PairID</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENG-dev-0000</td>\n",
       "      <td>The story is gripping and interesting.\\nIt's a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENG-dev-0001</td>\n",
       "      <td>The majority of Southeast Alaska 's area is pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENG-dev-0002</td>\n",
       "      <td>and from your post i think you are to young to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENG-dev-0003</td>\n",
       "      <td>The film 's success also made Dreamworks Anima...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENG-dev-0004</td>\n",
       "      <td>I am still confused about how I feel about thi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         PairID                                               Text\n",
       "0  ENG-dev-0000  The story is gripping and interesting.\\nIt's a...\n",
       "1  ENG-dev-0001  The majority of Southeast Alaska 's area is pa...\n",
       "2  ENG-dev-0002  and from your post i think you are to young to...\n",
       "3  ENG-dev-0003  The film 's success also made Dreamworks Anima...\n",
       "4  ENG-dev-0004  I am still confused about how I feel about thi..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dev_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5401f29-f1a8-4cf6-b69a-27cb435af378",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_xs1, dev_xs2 = map(list, zip(*[tuple(row['Text'].split('\\n')) for idx, row in raw_dev_df.iterrows()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e3dbb4-90bc-4d5f-8c45-861641ee562b",
   "metadata": {},
   "source": [
    "---\n",
    "## Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2274a8a2-1383-4add-8240-420f175f085b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = helper.get_model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aace3a43-489f-478a-b009-1596721bf771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson Correlation: 0.58\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "train_ys_ = model.predict(train_xs1, train_xs2)\n",
    "# evaluate\n",
    "# How well does the baseline correlate with human judgments?\n",
    "print(\"Pearson Correlation:\", round(np.corrcoef(train_ys, train_ys_)[0][1], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5c04d62-87c9-4c39-b021-ca143c59f49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dev\n",
    "dev_ys_ = model.predict(dev_xs1, dev_xs2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817eed15-27b1-4465-aab3-f7408a716b36",
   "metadata": {},
   "source": [
    "---\n",
    "## Output\n",
    "Submission file has two columns: 'PairID' and 'Pred_Score'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "699cfc7f-3c0d-4415-a53f-9b546fdf8caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dev_df['Pred_Score'] = dev_ys_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad88e997-518a-462d-9837-5aa53be55560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PairID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Pred_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENG-dev-0000</td>\n",
       "      <td>The story is gripping and interesting.\\nIt's a...</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENG-dev-0001</td>\n",
       "      <td>The majority of Southeast Alaska 's area is pa...</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENG-dev-0002</td>\n",
       "      <td>and from your post i think you are to young to...</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENG-dev-0003</td>\n",
       "      <td>The film 's success also made Dreamworks Anima...</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENG-dev-0004</td>\n",
       "      <td>I am still confused about how I feel about thi...</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         PairID                                               Text  Pred_Score\n",
       "0  ENG-dev-0000  The story is gripping and interesting.\\nIt's a...        0.17\n",
       "1  ENG-dev-0001  The majority of Southeast Alaska 's area is pa...        0.31\n",
       "2  ENG-dev-0002  and from your post i think you are to young to...        0.14\n",
       "3  ENG-dev-0003  The film 's success also made Dreamworks Anima...        0.22\n",
       "4  ENG-dev-0004  I am still confused about how I feel about thi...        0.12"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dev_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bd7dcf03-c3e2-4199-8ec7-76747df4b435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PairID</th>\n",
       "      <th>Pred_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENG-dev-0000</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENG-dev-0001</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENG-dev-0002</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENG-dev-0003</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENG-dev-0004</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         PairID  Pred_Score\n",
       "0  ENG-dev-0000        0.17\n",
       "1  ENG-dev-0001        0.31\n",
       "2  ENG-dev-0002        0.14\n",
       "3  ENG-dev-0003        0.22\n",
       "4  ENG-dev-0004        0.12"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dev_df[['PairID', 'Pred_Score']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "23330d87-a370-4f56-a804-75b6c133de28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./res/results/a/eng/base/0.csv'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.RESULTS_CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1dd22193-4390-4b63-900e-e262be4175a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dev_df[['PairID', 'Pred_Score']].to_csv(\n",
    "    config.RESULTS_CSV\n",
    "    , index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86caf7be-56e2-4ebf-9626-cccec722d871",
   "metadata": {},
   "source": [
    "---\n",
    "## Evaluation\n",
    "In SemEval 2024 Task 1, the effectiveness of an approach in Semantic Textual Relatedness will be rigorously evaluated through a set of established procedures and metrics on [CodaLab](https://codalab.lisn.upsaclay.fr/competitions/15715). \\\n",
    "This section outlines the evaluation process, detailing the specific metrics used, along with guidelines for assessing performance on various datasets throughout the competition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3623672-dbe8-4ace-b831-24d81ccecaed",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Metric\n",
    "The official evaluation metric is the Spearman correlation between the predicted similarity scores and the human-annotated gold scores. \\\n",
    "This metric helps in understanding how well the predicted scores align with human judgments. \\\n",
    "The evaluation script is available in the following GitHub repository: [Semantic Relatedness SemEval 2024 GitHub Repository](https://github.com/semantic-textual-relatedness/Semantic_Relatedness_SemEval2024)\n",
    "\n",
    "### Train\n",
    "\n",
    "For participants in Track A, which focuses on supervised methods, the provided dataset includes both a training set and a dev set. \\\n",
    "The training set, complete with labels, is crucial for building and refining your models. \\\n",
    "While evaluation on the training set is useful for checking implementation, the true measure of the sperformance lies in its generalization to unseen data, namely the dev and test sets.\n",
    "\n",
    "### Dev\n",
    "The development sets across all tracks come without labels. \\\n",
    "To evaluate the performance on the dev set, we need to submit results to the official evaluation hosted on CodaLab.\n",
    "\n",
    "### Test\n",
    "The final assessment will be based on the performance on the test set. \\\n",
    "Similar to the dev set evaluation, we are required to upload predictions for the test set to the official evaluation on CodaLab within the following time window:\n",
    "+ Evaluation Start: 10 January 2024\n",
    "+ Evaluation End: 31 January 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088b60d1-eac7-4dae-9f76-756a18944929",
   "metadata": {},
   "source": [
    "---\n",
    "# Submission\n",
    "Please follow steps shown below carefully to ensure the work is properly evaluated and considered in the competition.\n",
    "\n",
    "## 1. Create a CodaLab Account\n",
    "Begin by setting up an account on CodaLab, a platform widely used for academic competitions in machine learning and computational linguistics. \\\n",
    "We can create an account at [CodaLab's official website](https://codalab.lisn.upsaclay.fr/).\n",
    "\n",
    "## 2. Register for the Task\n",
    "Once the account is active, navigate to the [SemEval 2024 Task 1](https://codalab.lisn.upsaclay.fr/competitions/15715) on CodaLab and complete the registration process. \\\n",
    "This step is essential to ensure the participation and to gain access to submitting your results.\n",
    "\n",
    "## 3. Submit Results\n",
    "For developing, refining, and testing our methods, we will need to submit results for both the dev set and the test set for official evaluation. \\\n",
    "Ensure that the submissions adhere to the format specified in the [task guidelines](https://codalab.lisn.upsaclay.fr/competitions/15715#participate). \\\n",
    "Submissions that do not meet the required format may not be evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8756dd-908f-468b-b1e8-1eedda9a5cc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
